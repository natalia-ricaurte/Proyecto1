{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTQPoGCgJzNk"
      },
      "source": [
        "#Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCsBoTxQZ9J6",
        "outputId": "757c0648-3b14-4790-a3df-6748c0a14f53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (6.3.0)\n",
            "Requirement already satisfied: wcwidth in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from ftfy) (0.2.13)\n",
            "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the '/Users/nataliaricaurte/Desktop/Etapa2 - API/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: plot_confusion_matrix in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (0.0.2)\n",
            "Requirement already satisfied: matplotlib in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from plot_confusion_matrix) (3.9.2)\n",
            "Requirement already satisfied: numpy in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from plot_confusion_matrix) (1.26.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->plot_confusion_matrix) (4.54.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->plot_confusion_matrix) (24.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->plot_confusion_matrix) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->plot_confusion_matrix) (1.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->plot_confusion_matrix) (2.9.0.post0)\n",
            "Requirement already satisfied: pillow>=8 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->plot_confusion_matrix) (10.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->plot_confusion_matrix) (6.4.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->plot_confusion_matrix) (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->plot_confusion_matrix) (3.1.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->plot_confusion_matrix) (3.20.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->plot_confusion_matrix) (1.16.0)\n",
            "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the '/Users/nataliaricaurte/Desktop/Etapa2 - API/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Collecting wordcloud\n",
            "  Using cached wordcloud-1.9.3-cp39-cp39-macosx_10_9_x86_64.whl (173 kB)\n",
            "Requirement already satisfied: matplotlib in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from wordcloud) (3.9.2)\n",
            "Requirement already satisfied: pillow in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from wordcloud) (10.4.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from wordcloud) (1.26.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.4.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (6.4.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.1.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (4.54.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (24.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.20.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
            "Installing collected packages: wordcloud\n",
            "Successfully installed wordcloud-1.9.3\n",
            "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the '/Users/nataliaricaurte/Desktop/Etapa2 - API/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/nataliaricaurte/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/nataliaricaurte/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/nataliaricaurte/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "%pip install ftfy\n",
        "%pip install plot_confusion_matrix\n",
        "%pip install wordcloud\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import ftfy\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import joblib\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cqh20ZkZ99Z"
      },
      "source": [
        "#Creación Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kueqWDk-9DY1",
        "outputId": "f2078357-1ce8-4216-babc-dcfd02e5e25a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/nataliaricaurte/Desktop/Etapa2 - API/venv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exactitud: 0.97\n",
            "Recall: 0.9694926736182102\n",
            "Precisión: 0.969206607318536\n",
            "Puntuación F1: 0.969343426453166\n",
            "\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.97      0.98      0.97       250\n",
            "           4       0.97      0.97      0.97       268\n",
            "           5       0.97      0.96      0.97       292\n",
            "\n",
            "    accuracy                           0.97       810\n",
            "   macro avg       0.97      0.97      0.97       810\n",
            "weighted avg       0.97      0.97      0.97       810\n",
            "\n",
            "{3: [('', 307.93683581416553), ('salud', 82.85626706255475), ('atención', 65.98588620264049), ('servicios', 37.22729799610249), ('mental', 28.975696396482956), ('pacientes', 28.46306254028584), ('países', 24.560702519150418), ('primaria', 24.194617948142337), ('médicos', 24.014581478185423), ('enfermedades', 22.904032042662)], 4: [('', 333.44265082881844), ('educación', 66.28929006589918), ('estudiantes', 59.99506258491215), ('escuelas', 49.78338518397833), ('aprendizaje', 38.74028795968236), ('docentes', 34.263529012166664), ('alumnos', 32.27645203665484), ('evaluación', 31.484160411201653), ('escuela', 31.209186547999355), ('ocde', 26.74315950376427)], 5: [('', 368.1484320138849), ('mujeres', 129.3701026788973), ('género', 85.29727612811497), ('hombres', 47.30336790489764), ('igualdad', 40.34638380825083), ('trabajo', 30.680156924160016), ('derechos', 30.271637106799957), ('violencia', 27.97649561903655), ('países', 26.977190817275453), ('mujer', 24.42141735457415)]}\n"
          ]
        }
      ],
      "source": [
        "from procesamiento import tokenizer\n",
        "import os\n",
        "\n",
        "#Funciones individuales\n",
        "#----------------------------------------------------------------\n",
        "# Carga datos\n",
        "def cargar_datos_excel(excel_path):\n",
        "    datos = pd.read_excel(excel_path, engine='openpyxl')\n",
        "    return datos\n",
        "\n",
        "def cargar_datos_csv(csv_path):\n",
        "    datos = pd.read_csv(csv_path, encoding='latin1') \n",
        "    return datos\n",
        "\n",
        "# Cambiar a CVS\n",
        "def guardar_datos_csv(datos, output_path):\n",
        "    datos.to_csv(output_path, index=False, encoding='utf-8')\n",
        "\n",
        "# Corregir codificación texto\n",
        "def corregir_codificacion(datos, columna):\n",
        "    datos[columna] = datos[columna].apply(ftfy.fix_text)\n",
        "    return datos\n",
        "\n",
        "# imprimir palabras más frecuentes por categoría\n",
        "def print_most_frequent_words(pipeline, datos, columna_ods, categorias_ods, n=10):\n",
        "    tfidf_vectorizer = pipeline.named_steps['tfidf']\n",
        "    palabras_frecuentes_por_ods = {}\n",
        "    \n",
        "    for ods in categorias_ods:\n",
        "        texts_for_ods = datos[datos[columna_ods] == ods]['Textos_espanol']\n",
        "        X = tfidf_vectorizer.transform(texts_for_ods)\n",
        "        words = tfidf_vectorizer.get_feature_names_out()\n",
        "        sums = X.sum(axis=0).A1\n",
        "        word_freq = [(word, sums[idx]) for idx, word in enumerate(words)]\n",
        "        word_freq = sorted(word_freq, key=lambda x: x[1], reverse=True)\n",
        "        palabras_frecuentes_por_ods[ods] = word_freq[:n]  \n",
        "    \n",
        "    return palabras_frecuentes_por_ods\n",
        "        \n",
        "#----------------------------------------------------------------\n",
        "\n",
        "\n",
        "#Evaluación de metricas del modelo de clasificación\n",
        "def evaluar_modelo(y_test, y_pred):\n",
        "\n",
        "    print('Exactitud: %.2f' % accuracy_score(y_test, y_pred))\n",
        "    print(\"Recall: {}\".format(recall_score(y_test, y_pred, average='macro')))\n",
        "    print(\"Precisión: {}\".format(precision_score(y_test, y_pred, average='macro')))\n",
        "    print(\"Puntuación F1: {}\".format(f1_score(y_test, y_pred, average='macro')))\n",
        "\n",
        "    print(\"\\nReporte de Clasificación:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Creación Matriz de confusión\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Pipeline de procesamiento de datos\n",
        "def pipeline_procesamiento_datos(data, columna_texto, columna_ods):\n",
        "   \n",
        "    if isinstance(data, str) and data.endswith('.csv'):\n",
        "        datos = cargar_datos_csv(data)\n",
        "    elif isinstance(data, str) and data.endswith('.xlsx'):\n",
        "        datos = cargar_datos_excel(data)\n",
        "    elif isinstance(data, pd.DataFrame):\n",
        "        datos = data\n",
        "    else:\n",
        "        raise ValueError(\"El tipo de 'data' no es válido. Debe ser una ruta de archivo o un DataFrame.\")\n",
        "\n",
        "    # Creación del pipeline de preprocesamiento y modelo\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('tfidf', TfidfVectorizer(tokenizer=tokenizer)),\n",
        "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=0))\n",
        "    ])\n",
        "\n",
        "    # Dividir los datos en características (X) y etiquetas (y)\n",
        "    X_data = datos[columna_texto]\n",
        "    y_data = datos[columna_ods]\n",
        "\n",
        "    # Dividir los datos en entrenamiento y prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Ajustar el pipeline\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Hacer predicciones en el conjunto de prueba\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    evaluar_modelo(y_test, y_pred)\n",
        "\n",
        "    # Imprimir las palabras más frecuentes para cada categoría\n",
        "    frecuentes = print_most_frequent_words(pipeline, datos, columna_ods='sdg', categorias_ods=[3, 4, 5], n=10)\n",
        "\n",
        "    #print(frecuentes)\n",
        "    # calcular metricas \n",
        "    metricas = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'recall': recall_score(y_test, y_pred, average='macro'),\n",
        "        'precision': precision_score(y_test, y_pred, average='macro'),\n",
        "        'f1_score': f1_score(y_test, y_pred, average='macro')\n",
        "    }\n",
        "\n",
        "    print(frecuentes)\n",
        "\n",
        "    joblib.dump(pipeline, 'pipeline.joblib')\n",
        "    return {\n",
        "        'metricas': metricas, \n",
        "        'frecuentes': frecuentes,\n",
        "    }\n",
        "\n",
        "excel_path = '/Users/nataliaricaurte/Desktop/Etapa2 - API/Back/ODScat_345.xlsx'\n",
        "datos_corregidos = pipeline_procesamiento_datos(excel_path, 'Textos_espanol', 'sdg')\n",
        "\n",
        "# Cargar el modelo guardado en otra sesión\n",
        "def cargar_modelo():\n",
        "    # Cargar el vectorizador y el clasificador\n",
        "    current_dir = os.getcwd()\n",
        "    pipeline = joblib.load(os.path.join(current_dir, 'pipeline.joblib'))\n",
        "    return pipeline\n",
        "\n",
        "# Cargar el pipeline para hacer predicciones\n",
        "pipeline_cargado = cargar_modelo()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
